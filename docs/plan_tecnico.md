# **Plan T√©cnico de Implementaci√≥n: Sistema Distribuido de Entrenamiento IA con Raft**

Proyecto: Sistema Distribuido de Entrenamiento y Consumo de Modelos de IA  
Curso: Programaci√≥n Concurrente y Distribuida  
Arquitectura: H√≠brida (Python \+ Node.js \+ Java)  
Equipo: 5 Integrantes

## **1\. Resumen de Arquitectura**

El sistema se divide en tres capas l√≥gicas para cumplir con el requisito de m√∫ltiples lenguajes de programaci√≥n y las restricciones espec√≠ficas sobre el motor de Inteligencia Artificial:

1. **Capa de Cliente (LP1 \- Python):** \* Interfaz Desktop (GUI) para usuarios finales.  
   * Scripts de automatizaci√≥n para pruebas de estr√©s.  
   * Comunicaci√≥n v√≠a Sockets TCP puros.  
2. **Capa de Servidor y Consenso (LP2 \- Node.js):** \* Rol de "Workers" en el cl√∫ster.  
   * Implementaci√≥n del algoritmo RAFT para elecci√≥n de l√≠der y consistencia.  
   * Gesti√≥n de replicaci√≥n de archivos y servidor web de monitoreo.  
   * Act√∫a como orquestador de los procesos de IA.  
3. **Capa de C√≥mputo (LP3 \- Java):** \* "Core" de IA (Motor de red neuronal).  
   * Se ejecuta como subproceso (child process) invocado por Node.js.  
   * Realiza el entrenamiento matem√°tico intensivo utilizando concurrencia (Hilos/Threads) para aprovechar todos los n√∫cleos del procesador.

## **2\. Definici√≥n de Roles y Tareas (5 Integrantes)**

### **üîµ Equipo de Infraestructura y Consenso (Node.js)**

*Responsables de la red, sincronizaci√≥n de estados y visualizaci√≥n web.*

#### **Participante 1 (P1): Arquitecto de Algoritmo Raft**

*Responsable de la l√≥gica de estado y elecciones de l√≠der.*

* **Tarea 1.1: M√°quina de Estados.** Implementar la clase RaftNode con los estados Follower, Candidate, Leader y las transiciones l√≥gicas entre ellos.  
* **Tarea 1.2: Election Timeout.** Programar temporizadores aleatorios (ej. 150-300ms). Si el nodo no recibe comunicaci√≥n del l√≠der en este tiempo, se autopromueve a Candidato.  
* **Tarea 1.3: L√≥gica de Votaci√≥n (RequestVote RPC).** Validar los t√©rminos (term) recibidos y otorgar el voto √∫nicamente si el candidato tiene un log igual o m√°s actualizado.  
* **Tarea 1.4: Gesti√≥n del L√≠der.** Implementar el env√≠o peri√≥dico de mensajes *Heartbeats* para mantener la autoridad y evitar nuevas elecciones innecesarias.

#### **Participante 2 (P2): Ingeniero de Red TCP y Monitoreo**

*Responsable de Sockets, Persistencia en disco y Servidor HTTP.*

* **Tarea 2.1: Servidor TCP.** Crear el servidor usando el m√≥dulo nativo net de Node.js para recibir conexiones persistentes de Clientes y otros Nodos. *(Nota: Prohibido usar WebSockets o Socket.io)*.  
* **Tarea 2.2: Replicaci√≥n (AppendEntries RPC).** Implementar la l√≥gica para recibir archivos/logs y escribirlos f√≠sicamente en la carpeta local Disk n.  
* **Tarea 2.3: Servidor Web Embebido.** Usar el m√≥dulo http para servir un panel HTML que muestre: Rol actual del nodo, T√©rmino actual, y lista de Logs replicados en tiempo real.  
* **Tarea 2.4: Integraci√≥n con Java.** Implementar child\_process.spawn para ejecutar el JAR de IA autom√°ticamente cuando el consenso sobre un archivo de entrada se confirme.

### **‚òï Equipo de Motor de IA (Java \>= 8\)**

*Responsables del c√°lculo matem√°tico y concurrencia. **Restricci√≥n:** No usar frameworks de IA (TensorFlow, PyTorch, etc).*

#### **Participante 3 (P3): Matem√°tico Computacional (Core)**

*Responsable de la l√≥gica matem√°tica de las Redes Neuronales.*

* **Tarea 3.1: √Ålgebra Lineal.** Implementar clases desde cero para manejo de matrices: Matrix, Vector, y funciones de activaci√≥n Sigmoid, ReLU.  
* **Tarea 3.2: Forward Propagation.** Implementar el algoritmo de inferencia (multiplicaci√≥n de pesos \+ bias).  
* **Tarea 3.3: Backpropagation.** Implementar el algoritmo de entrenamiento y ajuste de pesos (Descenso del gradiente).  
* **Tarea 3.4: Serializaci√≥n.** Crear m√©todos para persistencia: saveModel(path) y loadModel(path) para guardar los pesos entrenados en formato binario o JSON manual.

#### **Participante 4 (P4): Ingeniero de Datos y Concurrencia**

*Responsable de eficiencia, uso de CPU y gesti√≥n de I/O.*

* **Tarea 4.1: Multi-threading.** Implementar java.lang.Thread o ExecutorService para dividir las operaciones matriciales grandes entre todos los n√∫cleos disponibles de la CPU.  
* **Tarea 4.2: Pipeline de Datos.** Leer los CSVs o im√°genes procesados por Node.js y normalizar los datos (escala 0-1) antes del entrenamiento.  
* **Tarea 4.3: Wrapper CLI.** Dise√±ar el public static void main para que acepte argumentos de l√≠nea de comandos:  
  * Modo Entrenamiento: java \-jar core.jar train \<input\_path\> \<output\_model\_id\>  
  * Modo Predicci√≥n: java \-jar core.jar predict \<model\_id\> \<input\_data\>

### **üêç Equipo de Cliente e Integraci√≥n (Python)**

*Responsable de la experiencia de usuario (UX) y validaci√≥n de calidad (QA).*

#### **Participante 5 (P5): Desarrollador Frontend y QA**

*Responsable de GUI y Pruebas de Estr√©s.*

* **Tarea 5.1: Cliente Desktop.** Construir interfaz gr√°fica (usando Tkinter o PyQt) con paneles para:  
  * Subir dataset (Entrenamiento).  
  * Consultar modelos disponibles y solicitar predicciones (Testeo).  
* **Tarea 5.2: Cliente Socket TCP.** Implementar la l√≥gica de conexi√≥n robusta. Debe manejar la reconexi√≥n autom√°tica si el Nodo L√≠der cambia y serializar mensajes (JSON sobre TCP).  
* **Tarea 5.3: Script de Estr√©s.** Desarrollar un script que genere y env√≠e **1000 archivos/peticiones aleatorias** de forma secuencial o paralela para validar que el algoritmo Raft mantiene la consistencia bajo carga alta.

## **3\. Especificaciones T√©cnicas**

### **3.1 Protocolo de Comunicaci√≥n (Sockets TCP)**

El formato de intercambio ser√° JSON String finalizado con un salto de l√≠nea \\n como delimitador de mensaje.

**A. Petici√≥n de Entrenamiento (Cliente \-\> L√≠der Node):**

{  
  "type": "TRAIN\_REQUEST",  
  "payload": {  
    "data\_content": "base64\_encoded\_or\_csv\_text",  
    "model\_name": "modelo\_grupo5\_v1"  
  }  
}

**B. Petici√≥n de Predicci√≥n (Cliente \-\> L√≠der Node):**

{  
  "type": "PREDICT\_REQUEST",  
  "payload": {  
    "model\_id": "modelo\_grupo5\_v1",  
    "input\_vector": \[0.5, 0.1, 0.9, 0.8\]  
  }  
}

**C. Consenso Raft (Node \-\> Node):**

{  
  "type": "APPEND\_ENTRIES",  
  "term": 5,  
  "leaderId": "Node\_A",  
  "prevLogIndex": 4,  
  "prevLogTerm": 4,  
  "entries": \[
    { "command": "STORE\_FILE", "filename": "data\_1.csv", "content": "..." }
  \],  
  "leaderCommit": 4  
}

### **3.2 Estructura de Directorios en el Nodo**

Cada Worker debe mantener esta estructura en su sistema de archivos local:

/node\_project  
  |-- server.js        (C√≥digo P1/P2 \- Node.js)  
  |-- core\_ia.jar      (C√≥digo P3/P4 \- Java Compilado)  
  |-- /disk            (Almacenamiento Simulado)  
      |-- /logs        (Historial de operaciones Raft)  
      |-- /datasets    (Inputs replicados desde el l√≠der)  
      |-- /models      (Modelos .bin generados por Java)

## **4\. Cronograma de Integraci√≥n (Pipeline)**

### **Fase 1: Esqueleto de Conectividad (D√≠as 1-2)**

* **P1/P2:** Lograr que 3 procesos Node.js se conecten por TCP entre s√≠ y mantengan canales abiertos.  
* **P3/P4:** Lograr que Java lea un CSV local, ejecute una operaci√≥n matem√°tica simple y guarde un archivo de salida.  
* **P5:** Crear ventana Python b√°sica que env√≠e un string JSON a Node.js y reciba un "ACK".

### **Fase 2: Implementaci√≥n de N√∫cleos (D√≠as 3-4)**

* **P1:** Implementar elecci√≥n de l√≠der. Prueba: Matar el proceso l√≠der y verificar que otro asume el mando en \<1 segundo.  
* **P2:** Implementar replicaci√≥n. Si el cliente env√≠a un archivo al l√≠der, este debe aparecer f√≠sicamente en la carpeta /disk de los 3 nodos.  
* **P3/P4:** Implementar la red neuronal real (Backpropagation) y validar convergencia (reducci√≥n de error).

### **Fase 3: Integraci√≥n H√≠brida (D√≠a 5\)**

* **P2:** Conectar Node con Java. Cuando Raft confirme ("commit") un archivo, Node lanza spawn('java', ...) autom√°ticamente.  
* **P2:** Node debe capturar el stdout de Java y, si es una respuesta de predicci√≥n, enrutarla de vuelta al socket del Cliente Python.

### **Fase 4: Pruebas y Despliegue (D√≠a 6\)**

* **Despliegue:** Configurar IPs est√°ticas en 3 laptops conectadas a la misma red LAN/WiFi.  
* **Estr√©s (P5):** Ejecutar el script de 1000 archivos.  
* **Verificaci√≥n:** Observar en los monitores Web (HTML) de P2 que los logs crecen sincronizados en las 3 laptops y no hay divergencias.

## **5\. Entregables Finales**

De acuerdo a lo solicitado en el examen final:

1. **C√≥digos Fuente:** Organizados en carpetas Client\_Python/, Server\_Node/, Core\_Java/. (Solo c√≥digo fuente, sin binarios innecesarios ni carpetas node\_modules o .class).  
2. **Informe PDF:** Documento que incluya el diagrama de arquitectura h√≠brida y el diagrama de flujo del protocolo Raft implementado.  
3. **Presentaci√≥n PDF:** Resumen ejecutivo para la exposici√≥n y defensa del proyecto.
